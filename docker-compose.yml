version: '2'
services:

  resultstore:
    image: mysql:5.6
    container_name: edx.devstack.analytics_pipeline.resultstore
    command: mysqld --character-set-server=utf8 --collation-server=utf8_bin
    environment:
      MYSQL_ROOT_PASSWORD: ""
      MYSQL_ALLOW_EMPTY_PASSWORD: "yes"
      MYSQL_DATABASE: 'reports'
    volumes:
      - ./.dev/volumes/resultstore:/var/lib/mysql

  namenode:
    image: uhopper/hadoop-namenode:2.7.2
    container_name: edx.devstack.analytics_pipeline.namenode
    hostname: namenode
    environment:
      - CLUSTER_NAME=devstack
    ports:
      - "50070:50070"
    command: ["/docker-command.sh"]
    volumes:
      - ./scripts/hadoop-docker-command.sh:/docker-command.sh
      - ./.dev/volumes/namenode:/hadoop/dfs/name

  datanode:
    image: uhopper/hadoop-datanode:2.7.2
    container_name: edx.devstack.analytics_pipeline.datanode
    hostname: datanode
    environment:
      CORE_CONF_fs_defaultFS: "hdfs://namenode:8020"
    depends_on:
      - namenode
    ports:
      - "50075:50075"
    command: ["/docker-command.sh"]
    volumes:
      - ./scripts/hadoop-docker-command.sh:/docker-command.sh
      - ./.dev/volumes/datanode:/hadoop/dfs/data

  resourcemanager:
    image: uhopper/hadoop-resourcemanager:2.7.2
    container_name: edx.devstack.analytics_pipeline.resourcemanager
    hostname: resourcemanager
    environment:
      CORE_CONF_fs_defaultFS: "hdfs://namenode:8020"
      YARN_CONF_yarn_log___aggregation___enable: 'true'
      YARN_CONF_yarn_nodemanager_aux___services: mapreduce_shuffle
      YARN_CONF_yarn_nodemanager_aux___services_mapreduce_shuffle_class: 'org.apache.hadoop.mapred.ShuffleHandler'
      MAPRED_CONF_mapreduce_framework_name: yarn
    depends_on:
      - namenode
      - datanode
    ports:
      - "127.0.0.1:8088:8088"      # resource manager web ui
    command: ["/docker-command.sh"]
    volumes:
      - ./scripts/hadoop-docker-command.sh:/docker-command.sh

  nodemanager:
    image: uhopper/hadoop-nodemanager:2.7.2
    container_name: edx.devstack.analytics_pipeline.nodemanager
    hostname: nodemanager
    environment:
      CORE_CONF_fs_defaultFS: "hdfs://namenode:8020"
      YARN_CONF_yarn_resourcemanager_hostname: resourcemanager
      YARN_CONF_yarn_log___aggregation___enable: 'true'
      YARN_CONF_yarn_nodemanager_aux___services: mapreduce_shuffle
      YARN_CONF_yarn_nodemanager_aux___services_mapreduce_shuffle_class: 'org.apache.hadoop.mapred.ShuffleHandler'
      YARN_CONF_yarn_nodemanager_vmem___check___enabled: 'false'
      MAPRED_CONF_mapreduce_framework_name: yarn
    depends_on:
      - resourcemanager
      - namenode
      - datanode
    ports:
      - "127.0.0.1:8042:8042"      # node manager web ui
      - "127.0.0.1:19888:19888"    # node manager job history server ui
    command: ["/docker-command.sh"]
    volumes:
      - ./scripts/hadoop-docker-command.sh:/docker-command.sh

  sparkmaster:
    image: bde2020/spark-master:2.1.0-hadoop2.7
    container_name: edx.devstack.analytics_pipeline.sparkmaster
    ports:
      - 8080:8080
      - 7077:7077
    env_file:
      - ./scripts/hadoop.env

  sparkworker:
    image: bde2020/spark-worker:2.1.0-hadoop2.7
    container_name: edx.devstack.analytics_pipeline.sparkworker
    depends_on:
      - sparkmaster
    environment:
      - SPARK_MASTER=spark://sparkmaster:7077
    ports:
      - 8081:8081
    env_file:
      - ./scripts/hadoop.env

  analyticspipelinedocker:
    image: edxops/analyticstack:3.0
    container_name: edx.devstack.analytics_pipeline
    volumes:
      - .:/edx/app/analytics_pipeline/analytics_pipeline
    command: ["/etc/bootstrap.sh", "-d"]
    depends_on:
      - resultstore
      - namenode
      - resourcemanager
      - nodemanager
      - datanode
      - sparkworker
    environment:
      HADOOP_COMMON_RESOURCE_MANAGER_HOST: "resourcemanager"
      HADOOP_DEFAULT_FS: "hdfs://namenode:8020"
      SPARK_MASTER_HOST: "spark://sparkmaster:7077"
      SPARK_MASTER_PORT: "7077"
      COMMON_MYSQL_MIGRATE_USER: root
      COMMON_MYSQL_MIGRATE_PASS: ""
